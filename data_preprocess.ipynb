{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='J:/VeReMi-Dataset/000_Select_data'\n",
    "os.chdir(data_path)\n",
    "datalist=[i for i in os.listdir(data_path) if '.tar.gz' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VeReMi_25200_28800_2019-11-27_16-28-30.tar.gz\n",
      "<bound method TarFile.getmembers of <tarfile.TarFile object at 0x0000029A7DC73730>>\n"
     ]
    }
   ],
   "source": [
    "df_list=[]\n",
    "label=[]\n",
    "OMNet_id=[]\n",
    "for i in datalist:\n",
    "    tar = tarfile.open(i, \"r:gz\")\n",
    "    print(i)\n",
    "    print(tar.getmembers)\n",
    "    for member in tar.getmembers():\n",
    "         f = tar.extractfile(member)\n",
    "         if member.name.find(\"Truth\")==-1:\n",
    "             if f is not None:\n",
    "                 label.append(int(member.name.split('/')[1].split('-')[3][1:]))\n",
    "                 OMNet_id.append(int(member.name.split('/')[1].split('-')[2]))\n",
    "                 t=pd.read_json(f.read(),lines=True)\n",
    "                 df_list.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\41131\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "normal=[]\n",
    "dos=[]\n",
    "dataset=np.vstack((df_list,OMNet_id,label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Sample:184.0\n",
      "val Sample:184.0\n",
      "train Sample:1475.0\n"
     ]
    }
   ],
   "source": [
    "ratio_train = 0.8 #训练集比例\n",
    "ratio_val = 0.1 #验证集比例\n",
    "ratio_test = 0.1 #测试集比例\n",
    "assert (ratio_train + ratio_val + ratio_val) == 1.0,'Total ratio Not equal to 1' ##检查总比例是否等于1\n",
    "cnt_test = round(dataset.shape[1] * ratio_test ,0)\n",
    "cnt_val = round(dataset.shape[1] * ratio_val ,0)\n",
    "cnt_train = dataset.shape[1] - cnt_test - cnt_val\n",
    "print(\"test Sample:\" + str(cnt_test))\n",
    "print(\"val Sample:\" + str(cnt_val))\n",
    "print(\"train Sample:\" + str(cnt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "train_list=[[]]\n",
    "val_list=[]\n",
    "test_list=[]\n",
    "t=dataset[:,1]\n",
    "for i in range(int(cnt_train)):\n",
    "    #np.append(train_list,dataset[:,i],axis=1)\n",
    "    train_list.append(dataset[:,i])\n",
    "for i in range(int(cnt_train) ,int(cnt_train + cnt_val)):\n",
    "    val_list.append(dataset[:,i])\n",
    "\n",
    "for i in range(int(cnt_train + cnt_val) ,int(cnt_train + cnt_val + cnt_test)):\n",
    "    test_list.append(dataset[:,i])\n",
    "print(1)\n",
    "#del dataset\n",
    "#gc.collect(dataset)\n",
    "del(train_list[0])\n",
    "del(val_list[0])\n",
    "del(test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def split_data(dataframes):\n",
    "    for frame in dataframes[0]:\n",
    "        for col in frame:\n",
    "            try:\n",
    "                for i in range(len(frame[col].values[0])):\n",
    "                    t_list = []\n",
    "                    for j in frame[col].values:\n",
    "                        t_list.append(j[i])\n",
    "                    frame[col + chr(88 + i)] = t_list\n",
    "                frame.drop(col, axis=1, inplace=True)\n",
    "            except TypeError:\n",
    "                continue\n",
    "\n",
    "def regularize(raw_data):\n",
    "    frame_list = []\n",
    "    for df in raw_data:\n",
    "        new_dataframe = pd.DataFrame(index=df.index)\n",
    "        columns = df.columns.tolist()\n",
    "        for c in columns:\n",
    "            if c != 'type':\n",
    "                d = df[c]\n",
    "                max_ = d.max()\n",
    "                min_ = d.min()\n",
    "                new_dataframe[c] = ((d - min_) / (max_ - min_)).tolist()\n",
    "            else:\n",
    "                new_dataframe[c] = df[c]\n",
    "        frame_list.append(new_dataframe)\n",
    "    return frame_list\n",
    "\n",
    "\n",
    "def data_convert(data):  # 数据正则与空值填充\n",
    "    ori_label = np.asarray(data[1]).astype('float64')\n",
    "    ori_id = np.asarray(data[2]).astype('float64')\n",
    "    data = regularize(data[0])\n",
    "    data[0].fillna(0.0, inplace=True)\n",
    "    data_regularized = data[0].values\n",
    "    label = []\n",
    "    id = []\n",
    "    print(len(data[0]))\n",
    "    for _ in range(len(data[0])):\n",
    "        label.append(ori_label[0])\n",
    "        id.append(ori_id[0])\n",
    "    for i in range(len(data)):\n",
    "        if i != 0:\n",
    "            data[i].fillna(0.0, inplace=True)\n",
    "            try:\n",
    "                data_regularized = np.vstack((data_regularized, data[i].values))\n",
    "                for _ in range(len(data[i])):\n",
    "                    label.append(ori_label[i])\n",
    "                    id.append(ori_id[i])\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return np.array(data_regularized), np.array(id),np.array(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train = np.array(train_list).T\n",
    "val = np.array(val_list).T\n",
    "test = np.array(test_list).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-5224fd6b4f25>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msplit_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0msplit_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0msplit_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mtrainX_regularized\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainid\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrainY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata_convert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mvalX_regularized\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata_convert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-7-9e5ea1446375>\u001B[0m in \u001B[0;36msplit_data\u001B[1;34m(dataframes)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0msplit_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataframes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mframe\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdataframes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "split_data(train)\n",
    "split_data(val)\n",
    "split_data(test)\n",
    "trainX_regularized, trainid,trainY = data_convert(train)\n",
    "valX_regularized, valid,valY = data_convert(val)\n",
    "testX_regularized, testid,testY = data_convert(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainX=np.row_stack((trainid,trainX_regularized))\n",
    "valX=np.row_stack((valid,valX_regularized))\n",
    "testX=np.row_stack((testid,testX_regularized))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('testX_processed.npy',testX)\n",
    "np.save('testY_processed.npy',testY)\n",
    "np.save('trainX_processed.npy',trainX)\n",
    "np.save('trainY_processed.npy',trainY)\n",
    "np.save('valX_processed.npy',valX)\n",
    "np.save('valY_processed.npy',valY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}