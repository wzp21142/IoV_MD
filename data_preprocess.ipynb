{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='J:/VeReMi-Dataset/000_Select_data'\n",
    "os.chdir(data_path)\n",
    "datalist=[i for i in os.listdir(data_path) if '.tar.gz' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VeReMi_25200_28800_2019-11-27_16-28-30.tar.gz\n"
     ]
    }
   ],
   "source": [
    "df_list=[]\n",
    "t=0\n",
    "label=[]\n",
    "for i in datalist:\n",
    "    tar = tarfile.open(i, \"r:gz\")\n",
    "    print(i)\n",
    "    for member in tar.getmembers():\n",
    "         f = tar.extractfile(member)\n",
    "         if member.name.find(\"Truth\")==-1:\n",
    "             if f is not None:\n",
    "                 label.append(int(member.name.split('/')[1].split('-')[3][1:]))\n",
    "                 t=pd.read_json(f.read(),lines=True)\n",
    "                 df_list.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'loc=0\\nfor i in dataset[1]:\\n    loc+=1\\n    if i == 0:\\n        normal.append(dataset[0][loc])\\n    elif i == 1:\\n        dos.append(dataset[0][loc])'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "normal=[]\n",
    "dos=[]\n",
    "dataset=np.vstack((df_list,label))\n",
    "#del df_list\n",
    "#gc.collect(df_list)\n",
    "'''loc=0\n",
    "for i in dataset[1]:\n",
    "    loc+=1\n",
    "    if i == 0:\n",
    "        normal.append(dataset[0][loc])\n",
    "    elif i == 1:\n",
    "        dos.append(dataset[0][loc])'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Sample:0.0\n",
      "val Sample:0.0\n",
      "train Sample:0.0\n"
     ]
    }
   ],
   "source": [
    "ratio_train = 0.8 #训练集比例\n",
    "ratio_val = 0.1 #验证集比例\n",
    "ratio_test = 0.1 #测试集比例\n",
    "assert (ratio_train + ratio_val + ratio_val) == 1.0,'Total ratio Not equal to 1' ##检查总比例是否等于1\n",
    "cnt_test = round(dataset.shape[1] * ratio_test ,0)\n",
    "cnt_val = round(dataset.shape[1] * ratio_val ,0)\n",
    "cnt_train = dataset.shape[1] - cnt_test - cnt_val\n",
    "print(\"test Sample:\" + str(cnt_test))\n",
    "print(\"val Sample:\" + str(cnt_val))\n",
    "print(\"train Sample:\" + str(cnt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "train_list=[[]]\n",
    "val_list=[]\n",
    "test_list=[]\n",
    "t=dataset[:,1]\n",
    "for i in range(int(cnt_train)):\n",
    "    #np.append(train_list,dataset[:,i],axis=1)\n",
    "    train_list.append(dataset[:,i])\n",
    "for i in range(int(cnt_train) ,int(cnt_train + cnt_val)):\n",
    "    val_list.append(dataset[:,i])\n",
    "\n",
    "for i in range(int(cnt_train + cnt_val) ,int(cnt_train + cnt_val + cnt_test)):\n",
    "    test_list.append(dataset[:,i])\n",
    "print(1)\n",
    "#del dataset\n",
    "#gc.collect(dataset)\n",
    "del(train_list[0])\n",
    "del(val_list[0])\n",
    "del(test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(dataframes):\n",
    "    for frame in dataframes[0]:\n",
    "        for col in frame:\n",
    "            try:\n",
    "                for i in range(len(frame[col].values[0])):\n",
    "                    t_list = []\n",
    "                    for j in frame[col].values:\n",
    "                        t_list.append(j[i])\n",
    "                    frame[col + chr(88 + i)] = t_list\n",
    "                frame.drop(col, axis=1, inplace=True)\n",
    "            except TypeError:\n",
    "                continue\n",
    "\n",
    "\n",
    "def regularize(raw_data):\n",
    "    frame_list = []\n",
    "    for df in raw_data:\n",
    "        new_dataframe = pd.DataFrame(index=df.index)\n",
    "        columns = df.columns.tolist()\n",
    "        for c in columns:\n",
    "            if c != 'type':\n",
    "                d = df[c]\n",
    "                max_ = d.max()\n",
    "                min_ = d.min()\n",
    "                new_dataframe[c] = ((d - min_) / (max_ - min_)).tolist()\n",
    "            else:\n",
    "                new_dataframe[c] = df[c]\n",
    "        frame_list.append(new_dataframe)\n",
    "    return frame_list\n",
    "\n",
    "\n",
    "def data_convert(data):  # 数据正则与空值填充\n",
    "    ori_label = np.asarray(data[1]).astype('float64')\n",
    "    data = regularize(data[0])\n",
    "    data[0].fillna(0.0, inplace=True)\n",
    "    data_regularized = data[0].values\n",
    "    label = []\n",
    "    for _ in range(len(data[0])):\n",
    "        label.append(ori_label[0])\n",
    "    for i in range(len(data)):\n",
    "        if i != 0:\n",
    "            data[i].fillna(0.0, inplace=True)\n",
    "            try:\n",
    "                data_regularized = np.vstack((data_regularized, data[i].values))\n",
    "                for _ in range(len(data[i])):\n",
    "                    label.append(ori_label[i])\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return np.array(data_regularized), np.array(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = train_list.T\n",
    "val = val_list.T\n",
    "test = test_list.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_data(train)\n",
    "split_data(val)\n",
    "split_data(test)\n",
    "trainX_regularized, trainY = data_convert(train)\n",
    "valX_regularized, valY = data_convert(val)\n",
    "testX_regularized, testY = data_convert(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('testX_processed.npy',testX_regularized)\n",
    "np.save('testY_processed.npy',testY)\n",
    "np.save('trainX_processed.npy',trainX_regularized)\n",
    "np.save('trainY_processed.npy',trainY)\n",
    "np.save('valX_processed.npy',valX_regularized)\n",
    "np.save('valY_processed.npy',valY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}